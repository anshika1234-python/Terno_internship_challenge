# ğŸš€ Predicting E-commerce Customer Churn with Smart AI

In todayâ€™s competitive e-commerce landscape, understanding **why customers stop engaging** is more critical than ever. For the **Terno Internship Challenge**, my goal was to build a compact yet intelligent model capable of identifying customers most at risk of churning â€” using only a small and noisy dataset.

---

## ğŸ§© The Challenge

The dataset simulated a typical e-commerce environment: a handful of behavioral features such as:

* `VisitsLast30Days`
* `TimeOnSite`
* `PurchaseCount`
* `HasSupportTicket`

The twist?
The data was *tiny* â€” only a few dozen rows â€” making it a test of precision and creativity rather than raw computation.
This wasnâ€™t about â€œdeep learning.â€ It was about **smart learning**.

---

## âš™ï¸ The Approach

I structured the project using a **clean machine learning pipeline**:

1. **Exploration & Cleaning** â€” checked variance, nulls, and distribution balance.
2. **Feature Scaling** â€” standardization for fair model training.
3. **SMOTE & Class Weights** â€” tackled class imbalance elegantly.
4. **Model Experiments** â€” tested Logistic Regression, RandomForest, and LightGBM.
5. **Evaluation** â€” through 5-fold Stratified CV and ROC-AUC scoring.

After experimentation, a **class-weighted RandomForest** emerged as the most stable model, giving:

* **ROC-AUC â‰ˆ 0.69**
* **Accuracy â‰ˆ 60â€“70% (depending on threshold)**
* **Robust interpretability via SHAP and permutation importance**

---

## ğŸ” Explainability Matters

Small data means every decision counts.
Using **SHAP values**, I visualized how features impacted predictions:

* ğŸ•’ `TimeOnSite` had the **strongest influence** on churn risk.
* ğŸ’¬ `HasSupportTicket` and `VisitsLast30Days` were secondary but insightful.
* ğŸ›’ `PurchaseCount` had minimal predictive power â€” customers bought less but didnâ€™t necessarily churn.

This transparency ensures that stakeholders can **trust the model**, not just its output.

---

## ğŸ¯ Key Learnings

* With small data, **robust validation** is more important than model complexity.
* **Explainability** should always accompany performance metrics.
* Even simple models can yield strategic insights when properly tuned.

---

## ğŸŒŸ The Outcome

A ready-to-deploy notebook and pipeline that:

* Detects churn-prone users
* Generates human-interpretable insights
* Is lightweight and production-friendly

This challenge was a perfect blend of data science fundamentals, model interpretability, and storytelling â€” proving that **impactful AI isnâ€™t about size, but about clarity.**

---

ğŸ“˜ *Project Repository:* [Terno Internship Challenge on GitHub](https://github.com/anshika1234-python/Terno_internship_challenge)
